2024-09-10 martes

# Proyecto de Machine Learning: Evaluaci√≥n 1  &hearts;

### Realizado por:
- **Katalina Escarlet Sep√∫lveda L√≥pez**  
- **Tamara Soledad Larenas Escobar**

---

## Descripci√≥n del Proyecto

Este proyecto aborda diversos problemas de Machine Learning utilizando algoritmos y t√©cnicas avanzadas para resolverlos. A continuaci√≥n, se presentan los problemas trabajados, los datasets utilizados y los resultados obtenidos.

---

## Problema 1: Predicci√≥n de precios de casas en California üè°

- **Objetivo**: Predecir el precio de una casa en California basado en sus caracter√≠sticas.
- **DataSet**: [California Housing Prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices)
  
### Preguntas:
1. **¬øQu√© caracter√≠sticas influyen m√°s en el valor de una casa?**  
- Haciendo un an√°lisis de regresi√≥n lineal multiple podemos ver que las variables que m√°s influyen en el valor de una casa son:

**1. median_income (ingreso medio)**
**2. housing_median_age (edad media de la vivienda)**
**3. households (grupo de personas que residen en una unidad de casa, para una cuadra)**
**4. total_bedrooms (total de habitaciones)**
   ![image](https://github.com/user-attachments/assets/e3960ade-0bf0-4df5-ad37-ccc8c0140153)

**Todas estas variables hacen que el valor de las viviendas sea mayor y est√°n se√±aladas de mayor influencia a menor, siendo mayor influyente el 1 y menor el 4.**

b)	Resultados de las m√©tricas de evaluaci√≥n:
**‚Ä¢	R¬≤ (R al cuadrado): 0.5667428164413046**
**‚Ä¢	MSE (Error Cuadr√°tico Medio): 5773039795.389613**
**‚Ä¢	RMSE (Ra√≠z del Error Cuadr√°tico Medio): 75980.52247378675**
**‚Ä¢	MAE (Error Absoluto Medio): 55840.90047785081**
![image](https://github.com/user-attachments/assets/eee3e69c-2949-48b9-b633-72a8d61d1803)

- **R¬≤:** El modelo no es completamente preciso ya que casi un 43% de la variabilidad en los precios de las casas no est√° explicada por estas caracter√≠sticas. Esto sugiere que hay otras variables importantes que no estamos considerando.

- **MSE (Error Cuadr√°tico Medio)** y **RMSE (Ra√≠z del Error Cuadr√°tico Medio):** El modelo tiene errores significativos al predecir el valor de las casas.

- **MAE (Error Absoluto Medio): **El error absoluto de las predicciones es de unos 55,840 d√≥lares.

**Conclusi√≥n:** Se podr√≠a mejorar estas estad√≠sticas tomando en cuenta las variables que no se utilizaron y/o utilizando otro tipo de an√°lisis que no sea el de ‚ÄúRegresi√≥n lineal multiple‚Äù.

---

## Problema 2: Clasificaci√≥n de correos electr√≥nicos como Spam üìß

- **Objetivo**: Clasificar correos electr√≥nicos en spam o no spam usando un modelo de clasificaci√≥n.
- **DataSet**: [Spambase Dataset](https://archive.ics.uci.edu/dataset/94/spambase)

### Preguntas:
1. **Justificaci√≥n del modelo utilizado**:  
   - **Modelo elegido es el √Årbol de Decisi√≥n.** Es un modelo de clasificaci√≥n que utiliza una estructura en forma de √°rbol para tomar decisiones basadas en las caracter√≠sticas de los datos.
- **Justificaci√≥n** es el √°rbol de decisi√≥n es f√°cil de entender y de poder interpretar. lo que permite a entender que carastericica est√° fluyendo en la clasificaci√≥n de un correo como spam o no spam.
![image](https://github.com/user-attachments/assets/1f78a9bf-13d5-4ce7-b9dc-09631c22d957)

2. **¬øQu√© caracter√≠sticas afectan m√°s en que un correo sea Spam?**  
- **char_freq _$(0.3317251157144086):** la alta frecuencia de este s√≠mbolo en un correo es un fuerte indicador de que el correo puede ser spam, ya que muchos correos spam usan s√≠mbolos de d√≥lar para llamar la atenci√≥n sobre ofertas o promociones.

- **word_freq_remove (0.16402401643589978):** la presencia de esta palabra remove, que a menudo se utiliza para ofrecer la opci√≥n de desuscribirse de correos electr√≥nicos, es com√∫n en correos spam.

- **char_freq_! (0.08511152217429538):** la alta frecuencia de signos ! de exclamaci√≥n es caracter√≠stica de correos que intentan captar la atenci√≥n de manera agresiva, lo que es t√≠pico en los mensajes de spam.

![image](https://github.com/user-attachments/assets/0b9cfa90-6f91-44d0-9cb6-e169d1e4b160)

**3.Usar las m√©tricas: Tasa de Error, Exactitud, Matriz de confusi√≥n, tasa de positivos verdaderos, tasa de positivos falsos, Precisi√≥n, F1-Score. Investigar cu√°l(es) de estas m√©tricas es m√°s acertada para este caso y explicar su interpretaci√≥n. **

###### 1.TASA DE ERROR:  0.1007

- La tasa de error mide la proporci√≥n de predicciones incorrectas sobre el total de predicciones. En este caso el 0.10 de las predicciones son incorrectas.

###### 2.EXACTITUD (ACCURACY): 0.8993

- Explicaci√≥n: El modelo tiene una exactitud del 0.89 lo que indica que el 0.89 de las veces el modelo predice correctamente si un correo es spam o no.

###### 3.LA MATRIZ DE CONFUSI√ìN TIENE 4 CATEGOR√çA:

1. **Verdaderos Positivos (VP): 507 **Correos clasificados correctamente como spam.
2. **Falsos Positivos (FP):  69** Correos clasificados incorrectamente como spam.
3. **Verdaderos Negativos (VN): 735** Correos clasificados correctamente como no spam.
4. **Falsos Negativos (FN): 70** Correos clasificados incorrectamente como no spam.

###### 4.TASA DE POSITIVOS VERDADEROS (TRUE POSITIVE RATE): VALOR PARA SPAM 0.88

- La tasa de positivos verdaderos o recuperaci√≥n para la clase spam indica la proporci√≥n de correos spam que fueron correctamente identificados como spam.

###### 5.TASA DE POSITIVOS FALSOS (FALSE POSITIVE RATE): PRECISI√ìN PARA NO SPAM 0.09

-  La tasa de positivos falsos indica la proporci√≥n de correos no spam que fueron incorrectamente clasificados como spam. Un valor bajo es deseable para evitar que correos leg√≠timos sean marcados err√≥neamente como spam.

**1. TN (Verdaderos Negativos) = 735**
**2. FP (Falsos Positivos) = 69**
**3. FN (Falsos Negativos) = 70**
**4. TP (Verdaderos Positivos) = 507**
**FPR= 69 + 735 / 69 = 0.09**

###### 6.PRECISI√ìN: VALOR: 0.8802

- La precisi√≥n indica la proporci√≥n de verdaderos positivos sobre el total de positivos predichos. De todos los correos que el modelo clasific√≥ como spam, el 0.88 realmente son spam.

###### 7.F1-SCORE: VALOR: 0.8794

-  el F1-Score del 0.87 sugiere que el modelo tiene un buen equilibrio entre identificar correctamente los correos spam y minimizar los falsos positivos.

###### 8.LA M√âTRICA MAS ACETADA PARA MI SERIA:

Seria el El F1-Score es una m√©trica que balancea la precisi√≥n y la tasa de verdaderos positivos. En el caso de un filtro de spam, los falsos positivos serian bloquear correos importantes y los falsos negativos serian permitir correos no deseados son igualmente problem√°ticos. El F1-Score es muy importante ya que combina precisi√≥n y la tasa de verdaderos positivos para ofrecer una visi√≥n m√°s equilibrada del rendimiento del modelo, evitando priorizar una m√©trica sobre la otra.

**Interpretaci√≥n:** Un buen valor de F1-Score indica que el modelo tiene un buen balance entre precisi√≥n y TPR, lo cual es √∫til en situaciones donde ambos errores deben ser minimizados.

![image](https://github.com/user-attachments/assets/472656d0-d36d-4d3d-9873-d800670201e7)

---

## Problema 3: Sistema de Recomendaci√≥n de Pel√≠culas üé¨

- **Objetivo**: Recomendar pel√≠culas a un usuario basado en sus preferencias y las de otros usuarios.
- **DataSet**: [MovieLens 20M Dataset](https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset?select=movie.csv)

### Preguntas:
1. **¬øCu√°l pel√≠cula recomendar√≠an si se quiere ver una pel√≠cula de terror?**
   - Recomendar√≠a las siguientes 3 pel√≠culas de terror, que tienen las calificaciones m√°s altas:
   
| Giorgino (1994)  | Adventure - Drama - Horror  | 5.0   |
| ------------ | ------------ | ------------ |
|  Dream Demon (1988)  |  Horror   |  5.0 |
| tales that witness madness (1973)  | Comedy - Horror - Mystery - Sci-Fi   | 5.0  |

![image](https://github.com/user-attachments/assets/a0a50dae-db80-4902-a0e7-624a31223ed8)

2. **¬øQu√© pel√≠cula recomendar√≠an si mi √∫ltima pel√≠cula fue Toy Story?**  

  - Recomendar√≠a las pel√≠culas que est√©n dentro de los g√©neros de Toy Story y que tengan una alta puntuaci√≥n en su calificaci√≥n.

| Shaolin Temple 2: Kids from Shaolin (Shao Lin xiao zi) (Kids from Shaolin) (1984)  | Action - Comedy   |  5.0 |
| ------------ | ------------ | ------------ |
|**The Encounter (2010)**     | **Children - Drama**   | 5.0  |
| **The great match (2007)**    |   **Comedy** | 5.0  |

![image](https://github.com/user-attachments/assets/5cc0d1bb-f6ea-4ed2-98fe-8d42a1023c33)


---

## Problema 4: Detecci√≥n de Fraude en Transacciones Bancarias üí≥

- **Objetivo**: Detectar si una transacci√≥n bancaria es fraudulenta utilizando un SVM (Support Vector Machine).
- **DataSet**: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

### Preguntas:
**1. ¬øQu√© kernel ser√≠a m√°s educado para abordar este problema? Justifique su respuesta.**
###### - El kernel RBF (Radial Basis Function) ser√≠a una buena opci√≥n para detectar fraude en tarjetas de cr√©dito usando un modelo SVM. Aqu√≠ te explico por qu√©:

**1. Relaciones no lineales: **Las variables del dataset (V1 a V28) no tienen una relaci√≥n directa y simple con el fraude. El kernel RBF es excelente para captar patrones complejos y no lineales en los datos.

**2. Manejo de datos complejos:** El RBF transforma los datos en un espacio m√°s amplio, lo que ayuda a separar mejor las transacciones fraudulentas de las leg√≠timas.

**3. Desbalance de clases:** Dado que el fraude es mucho menos com√∫n que las transacciones normales, ajustar el modelo con el kernel RBF puede ayudar a identificar mejor estas transacciones raras pero cr√≠ticas.

###### En resumen, el kernel RBF es ideal porque puede manejar la complejidad y los patrones no lineales en tus datos, lo que mejora la detecci√≥n de fraudes.
![image](https://github.com/user-attachments/assets/b2d3dd16-607c-4726-90d4-5b2f7cf155f0)

![image](https://github.com/user-attachments/assets/dc7007ac-1232-4ea8-ad21-1fcc16ce68ba)
![image](https://github.com/user-attachments/assets/695578e4-0460-410d-b33c-65d1960b7a21)

**1. Comparar las m√©tricas de: Precisi√≥n, Puntaje-F1, Puntaje Recall y Exactitud, explique cual se ajusta mejor para medir la calidad del modelo y porqu√© **

**Resultados de las m√©tricas:**

- **Precisi√≥n: 0.95**
El 95% de las transacciones clasificadas como fraudulentas realmente son fraudulentas. El modelo es bueno evitando falsos positivos, pero no da informaci√≥n completa sobre la capacidad del modelo para detectar todos los fraudes reales.

- **Recall: 0.80**
El 80% de las transacciones fraudulentas han sido correctamente identificadas, el modelo es efectivo en identificar una gran parte de los fraudes reales.

- **Puntaje F1: 0.87**
es una buena m√©trica general cuando es importante tanto identificar la mayor√≠a de los fraudes (recall) como asegurar que las transacciones identificadas como fraudulentas sean en realidad fraudulentas (precisi√≥n).

- **Exactitud: 1.00**
El modelo ha clasificado correctamente el 100% de las transacciones. Aunque parece excelente, la exactitud puede ser enga√±osa en conjuntos de datos desbalanceados como el de detecci√≥n de fraude, donde las transacciones fraudulentas son mucho menos frecuentes que las transacciones leg√≠timas.

![image](https://github.com/user-attachments/assets/a69da6d9-1162-4af3-8cc6-161d0fe5e4c3)


**En conclusi√≥n** la m√©trica que seria mas precisa o se ajustar√≠a mejor a este modelo ser√≠a la de puntaje F1 por que en problemas de detecci√≥n de fraude, la mayor√≠a de las transacciones son leg√≠timas, lo que significa que un modelo podr√≠a tener una precisi√≥n alta solo porque clasifica casi todo como no fraudulento. Pero eso no garantiza que sea bueno detectando fraudes reales.

Por eso, el puntaje F1 es √∫til, ya que combina tanto la precisi√≥n como el recall. Detectar la mayor cantidad de fraudes (recall) es importante, pero tambi√©n lo es evitar marcar transacciones leg√≠timas como fraudulentas (precisi√≥n). El F1 ayuda a equilibrar amb

---

## Problema 5: Clasificaci√≥n de flores utilizando un Perceptr√≥n üå∏

- **Objetivo**: Clasificar dos tipos de flores usando un Perceptr√≥n simple con el conjunto de datos Iris, simplificado para dos clases y dos caracter√≠sticas.
- **DataSet**: Iris Dataset (scikit-learn)

![image](https://github.com/user-attachments/assets/00331da9-8839-40e5-aa3a-d5ffc4f00ab1)
![image](https://github.com/user-attachments/assets/235cbbbd-aa8a-4dd4-8348-254384992297)
![image](https://github.com/user-attachments/assets/6bd6ada8-53d1-46d9-b4a9-713d1156e902)

---

## Conclusi√≥n ‚ú®

A lo largo de este proyecto, abordamos una variedad de problemas utilizando diferentes t√©cnicas de Machine Learning, desde regresi√≥n hasta clasificaci√≥n y sistemas de recomendaci√≥n. Evaluamos los modelos utilizando diversas m√©tricas, y ajustamos los algoritmos para obtener el mejor rendimiento posible.

---
